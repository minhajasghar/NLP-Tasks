{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "IHij63Xlva7E",
        "outputId": "4a2f0456-fee5-435f-ddf7-930e0917912d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import joblib\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "SEuuxpw_vkJ7"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Load both JSON files\n",
        "def load_json(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        data = [json.loads(line) for line in f]\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "df1 = load_json(r\"C:\\Users\\minha\\Downloads\\News Headlines Dataset\\Sarcasm_Headlines_Dataset_v2.json\")\n",
        "df2 = load_json(r\"C:\\Users\\minha\\Downloads\\News Headlines Dataset\\Sarcasm_Headlines_Dataset_v2.json\")\n",
        "\n",
        "# Combine datasets\n",
        "df = pd.concat([df1, df2], ignore_index=True)\n",
        "\n",
        "# Keep only 'headline' and 'is_sarcastic' columns\n",
        "df = df[['headline', 'is_sarcastic']]\n",
        "df.rename(columns={'is_sarcastic': 'label'}, inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headline</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>thirtysomething scientists unveil doomsday clo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>dem rep. totally nails why congress is falling...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>eat your veggies: 9 deliciously different recipes</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>inclement weather prevents liar from getting t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>mother comes pretty close to using word 'strea...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57233</th>\n",
              "      <td>jews to celebrate rosh hashasha or something</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57234</th>\n",
              "      <td>internal affairs investigator disappointed con...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57235</th>\n",
              "      <td>the most beautiful acceptance speech this week...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57236</th>\n",
              "      <td>mars probe destroyed by orbiting spielberg-gat...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57237</th>\n",
              "      <td>dad clarifies this not a food stop</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>57238 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                headline  label\n",
              "0      thirtysomething scientists unveil doomsday clo...      1\n",
              "1      dem rep. totally nails why congress is falling...      0\n",
              "2      eat your veggies: 9 deliciously different recipes      0\n",
              "3      inclement weather prevents liar from getting t...      1\n",
              "4      mother comes pretty close to using word 'strea...      1\n",
              "...                                                  ...    ...\n",
              "57233       jews to celebrate rosh hashasha or something      1\n",
              "57234  internal affairs investigator disappointed con...      1\n",
              "57235  the most beautiful acceptance speech this week...      0\n",
              "57236  mars probe destroyed by orbiting spielberg-gat...      1\n",
              "57237                 dad clarifies this not a food stop      1\n",
              "\n",
              "[57238 rows x 2 columns]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\minha\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\minha\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to\n",
            "[nltk_data]     C:\\Users\\minha\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords, wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Download required data\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text)\n",
        "    text = re.sub(r'@\\w+|#', '', text)\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # remove punctuation\n",
        "    words = text.split()\n",
        "    words = [lemmatizer.lemmatize(w) for w in words if w not in stop_words]\n",
        "    return ' '.join(words)\n",
        "\n",
        "df['cleaned'] = df['headline'].astype(str).apply(clean_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "gsGVvBpr1zrP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.851240391334731\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86      5953\n",
            "           1       0.86      0.82      0.84      5495\n",
            "\n",
            "    accuracy                           0.85     11448\n",
            "   macro avg       0.85      0.85      0.85     11448\n",
            "weighted avg       0.85      0.85      0.85     11448\n",
            "\n",
            "Model and vectorizer saved successfully.\n"
          ]
        }
      ],
      "source": [
        "# Vectorize\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(df['cleaned'])\n",
        "y = df['label']\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Save model\n",
        "os.makedirs(\"sarcasm_model\", exist_ok=True)\n",
        "joblib.dump(model, \"sarcasm_model/model.pkl\")\n",
        "joblib.dump(vectorizer, \"sarcasm_model/vectorizer.pkl\")\n",
        "print(\"Model and vectorizer saved successfully.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
